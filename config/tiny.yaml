name: "emil_tiny"
train:
  batch_size: 4
  total_token_proc: 4_000_000
  cos_an_lr_max: 3.0e-4
  cos_an_lr_min: 1.0e-6
  grad_clip_max_norm: 0.01
  eval_steps: 5
model:
  context_length: 128
  num_layers: 2
  d_model: 256
  num_heads: 4
  d_ff: 1344
  rope_theta: 10_000
optimizer:
  learning_rate: 5.0e-4
  betas: 
    - 0.9
    - 0.999
  eps: 1.0e-8
  weight_decay: 0.0